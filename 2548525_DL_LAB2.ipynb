{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LAB-2 : Making a feed forward neural network using Fashion MINST dataset"
      ],
      "metadata": {
        "id": "bnCaM0hCuE90"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here for a better learning purposes i have used a guided learning model from gemini to learn better rather than just taking out the code from any of the LLMs."
      ],
      "metadata": {
        "id": "a0d2rR5UuYYL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets proceed with importing of the libraries, here we will import necessary libraries at a time to know properly which one is being used where."
      ],
      "metadata": {
        "id": "Fc1VS30YuvZw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprosessing of the MINST dataset"
      ],
      "metadata": {
        "id": "j6gv48gUvJK-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initially we use a torchvision.datasets.FashionMINST to import the dataset. and then process to convert the image into a tensor, and then futher normalise it down.\n",
        "\n",
        "why is normalisation important?  \n",
        "* Normalization keeps input ranges consistent\n",
        "* This makes gradient updates stable and faster\n",
        "* It prevents some features (pixels) from dominating learning just because of scale"
      ],
      "metadata": {
        "id": "diOtKCRmvQOc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8XfVhTNzoQL_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n"
      ],
      "metadata": {
        "id": "lkdSFdtFywXT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset= datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")"
      ],
      "metadata": {
        "id": "l12CRGksw348",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15f9f19f-f3d1-4cc5-82d8-723f3ba8b016"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 10.7MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 206kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.38MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 10.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6l02MZMyTwH",
        "outputId": "c0e0bd4d-e2b2-4581-b236-36de87bd35bc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset FashionMNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               ToTensor()\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "joO15NFvyXCI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    transform=transform,\n",
        "    download=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "G8QYrqtwDvLn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now only inspect if got the things right from our previous steps"
      ],
      "metadata": {
        "id": "t6s-i5216gXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(iter(train_loader))\n",
        "\n",
        "print(images.shape)\n",
        "print(labels.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVa1iDEu68gs",
        "outputId": "50b03d38-dbce-4ed5-d95b-bf8b1883bdc6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 1, 28, 28])\n",
            "torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now see that we have got our expected results.\n",
        "we can now see that our image size is [1,28,28] which is not in the shape that our nn.module expects.  \n",
        "Therefore we will reduce the shape of it by doinh 1x28x28=784, this process is called flattening our image. as our nn.module only takes vectors as input."
      ],
      "metadata": {
        "id": "JwiTOI7i8jhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc1=nn.Linear(784,392)\n",
        "    self.fc2=nn.Linear(392,196)\n",
        "    self.fc3=nn.Linear(196,49)\n",
        "    self.fc4=nn.Linear(49,10)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x=x.view(x.size(0),-1)\n",
        "    x=torch.relu(self.fc1(x))\n",
        "    x=torch.relu(self.fc2(x))\n",
        "    x=torch.relu(self.fc3(x))\n",
        "    x=self.fc4(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "0z-jsnpi6_oF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now just testing an instance"
      ],
      "metadata": {
        "id": "n2p5zOHyD3Hr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP()\n",
        "images, labels = next(iter(train_loader))\n",
        "outputs = model(images)\n",
        "print(outputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAfkNP0sDKVW",
        "outputId": "28d6ab9a-382e-4da6-a04f-424404a36e10"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks good"
      ],
      "metadata": {
        "id": "FyqrTG0QD8nZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss Function and Optimizer"
      ],
      "metadata": {
        "id": "YbOSCdIIEIdh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CrossEntropyLoss is used for multi-class classification problems, where the model predicts one out of several discrete classes. It internally applies the Softmax function to convert raw outputs (logits) into class probabilities and then computes the negative log-likelihood loss.\n",
        "\n",
        "The Adam optimizer is chosen because it combines the benefits of momentum and adaptive learning rates. It adjusts the learning rate for each parameter individually, leading to faster convergence and stable training. A learning rate of 0.001 provides a balanced trade-off between training speed and stability."
      ],
      "metadata": {
        "id": "72Vkl3IDFqzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "model = MLP()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "S-luJPJADMcV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Loop (Loss + Accuracy Monitoring)"
      ],
      "metadata": {
        "id": "4n85-FJ7EL4i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The model is set to training mode using model.train(), enabling gradient computation and ensuring that all layers behave correctly during training.\n",
        "* Before computing gradients for the current batch, previously accumulated gradients are cleared. This prevents incorrect gradient accumulation across batches.\n",
        "* During the forward pass, input images are propagated through the neural network to produce output logits. The loss function then measures the discrepancy between predicted outputs and true class labels, quantifying how well the model is performing.\n",
        "* The backward pass computes gradients of the loss with respect to all trainable parameters using backpropagation. The optimizer then updates the weights based on these gradients to minimize the loss."
      ],
      "metadata": {
        "id": "qNQdJ33zFGSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8RMM2ViD_ET",
        "outputId": "86fe3e9f-1624-485a-e53b-3db5d239e1dd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 971.8550, Accuracy: 80.97%\n",
            "Epoch [2/5], Loss: 695.1672, Accuracy: 86.44%\n",
            "Epoch [3/5], Loss: 621.0059, Accuracy: 87.77%\n",
            "Epoch [4/5], Loss: 573.7068, Accuracy: 88.72%\n",
            "Epoch [5/5], Loss: 542.8310, Accuracy: 89.25%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training loss consistently decreases across epochs, indicating that the neural network is learning meaningful patterns from the data. Simultaneously, training accuracy improves from approximately 81% to 89%, demonstrating better classification performance as training progresses.\n",
        "\n",
        "This trend confirms that the optimizer and learning rate are well chosen and that the model is converging without instability or divergence."
      ],
      "metadata": {
        "id": "kz5e7xdoFUpm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation on Test Data"
      ],
      "metadata": {
        "id": "ThUNJBIiEUfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():                         ## as gradients are not required for testing.\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "test_accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjmlUgArEHnC",
        "outputId": "2c9404be-6ae1-4d6d-fbd8-8f124f4d4e2b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 87.70%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model achieves a test accuracy of 87.70%, which is slightly lower than the training accuracy. This indicates good generalization with minimal overfitting. The small gap between training and test accuracy confirms that the model has learned robust features rather than memorizing the training data."
      ],
      "metadata": {
        "id": "PvTqavGJE9Q9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Role of ReLU and Linear Output**\n",
        "\n",
        "* ReLU activation introduces non-linearity, enabling the network to learn complex patterns.\n",
        "* Without ReLU, multiple linear layers would behave like a single linear transformation.\n",
        "* The output layer is linear because CrossEntropyLoss internally applies Softmax."
      ],
      "metadata": {
        "id": "uENDKLoHIloT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Forward Pass**\n",
        "\n",
        "* Input data flows through each layer of the network.\n",
        "* Linear transformations and activations compute predicted outputs.\n",
        "* The final output represents raw class scores (logits)."
      ],
      "metadata": {
        "id": "IEd0nffPIvxz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Backward Pass**\n",
        "\n",
        "* The loss function computes error between predictions and true labels.\n",
        "* Backpropagation calculates gradients of loss with respect to weights\n",
        "* Gradients indicate how much each parameter contributed to the error."
      ],
      "metadata": {
        "id": "7vCDBi0XI4cN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gradient Updates**\n",
        "\n",
        "* The optimizer (Adam/SGD) updates weights using computed gradients.\n",
        "* Learning rate controls the step size of weight updates.\n",
        "* This process minimizes the loss function over time."
      ],
      "metadata": {
        "id": "ejL0G0fwI6io"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Loss and Accuracy**\n",
        "\n",
        "* Loss measures how incorrect the predictions are.\n",
        "* Accuracy measures how many predictions are correct.\n",
        "* Monitoring both ensures proper learning and avoids underfitting/overfitting."
      ],
      "metadata": {
        "id": "V2yxzE3CI-m9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation on Test Data**\n",
        "\n",
        "* The model is tested on unseen data to measure generalization.\n",
        "* model.eval() disables dropout and batch normalization effects.\n",
        "* No gradients are computed during evaluation for efficiency."
      ],
      "metadata": {
        "id": "U5qSMJKGJBIJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Impact of Hyperparameters**  \n",
        "\n",
        "**Learning Rate**.  \n",
        "Too high → unstable training.  \n",
        "Too low → slow convergence.  \n",
        "\n",
        "**Batch Size**.  \n",
        "Small batch → noisy but generalizable updates.  \n",
        "Large batch → stable but memory intensive.  \n",
        "\n",
        "**Number of Epochs**.  \n",
        "Too few → underfitting.  \n",
        "Too many → overfitting.  "
      ],
      "metadata": {
        "id": "-OCHZmdnJC0Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####ADV task 1: Experimenting with multiple hidden layer and dicussing the trade off"
      ],
      "metadata": {
        "id": "aGuS-f0AGdyQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1 : I define a flexible MLP model so that i don't have to rewrite the code every time i want to change the number of hidden layers."
      ],
      "metadata": {
        "id": "tImGkw0fGpEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FlexibleMLP(nn.Module):\n",
        "    def __init__(self, hidden_layers):\n",
        "        super().__init__()\n",
        "\n",
        "        layers = []\n",
        "        input_size = 784\n",
        "\n",
        "        for hidden_size in hidden_layers:\n",
        "            layers.append(nn.Linear(input_size, hidden_size))\n",
        "            layers.append(nn.ReLU())\n",
        "            input_size = hidden_size\n",
        "\n",
        "        layers.append(nn.Linear(input_size, 10))\n",
        "\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.network(x)\n"
      ],
      "metadata": {
        "id": "oUepV5kkEhHC"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(hidden_layers, epochs=5):\n",
        "    model = FlexibleMLP(hidden_layers)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return running_loss, accuracy\n"
      ],
      "metadata": {
        "id": "uFr1PylNG1-6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "configs = {\n",
        "    \"1 Hidden Layer\": [128],\n",
        "    \"3 Hidden Layers\": [392, 196, 49],\n",
        "    \"5 Hidden Layers\": [512, 256, 128, 64, 32]\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, layers in configs.items():\n",
        "    loss, acc = train_and_evaluate(layers)\n",
        "    results[name] = (loss, acc)\n",
        "    print(f\"{name} → Test Accuracy: {acc:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsdMpIkIHBBR",
        "outputId": "8567ad44-b6b9-464b-f54a-23142f176295"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Hidden Layer → Test Accuracy: 86.04%\n",
            "3 Hidden Layers → Test Accuracy: 87.66%\n",
            "5 Hidden Layers → Test Accuracy: 85.92%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretation**\n",
        "\n",
        "Increasing depth initially improves learning capacity, but beyond a point, deeper networks show diminishing returns and may overfit due to excessive model complexity."
      ],
      "metadata": {
        "id": "hkD1_N9nHPvi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In simple terms:  \n",
        "1 hidden layer - underfitting.  \n",
        "3 hidden layer - good training.  \n",
        "5 hidden layer - slightly overfitting."
      ],
      "metadata": {
        "id": "B3jZ82EAHT3m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An optimal network depth provides sufficient expressive power without memorizing training data. In this experiment, a 3-hidden-layer architecture achieves the best generalization performance."
      ],
      "metadata": {
        "id": "uE2b_oaKHx2h"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9NKFS2FQHush"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}